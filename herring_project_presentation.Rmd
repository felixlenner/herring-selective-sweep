---
title: "Herring Selective Sweep"
subtitle: "Bioinformatics 3MR103"
author: "Love Chrisson, Felix Lenner & Ben Titmus"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
```{css, echo=FALSE}
pre {
  white-space: pre-wrap;
}
.nowrap pre{
  white-space: nowrap;
}
.tiny .remark-code {
  font-size: 60% !important;
}
```

```{r, setup, include=FALSE}
# Set working directory
knitr::opts_knit$set(root.dir = '~/project/notebook-test/herring_project_presentation/herring-selective-sweep-presentation/')

# Set paths to files
eigenvec_path = 'data/chr4_pca.eigenvec'
eigenval_path = 'data/chr4_pca.eigenval'

atlantic_freq_path = 'data/chr4_atlantic.frq'
baltic_freq_path = 'data/chr4_baltic.frq'

atlantic_het_path = 'data/chr4_atlantic.hwe'
baltic_het_path = 'data/chr4_baltic.hwe'

annotations_path = 'data/original_already_annotated.txt'

# Set cache TRUE or FALSE 
knitr::opts_chunk$set(cache = FALSE)

# Don't change
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  x <- stringr::str_replace(x, "^[[:blank:]]?([^*].+?)[[:blank:]]*#<<[[:blank:]]*$", "*\\1")
  hook_source(x, options)
})
```

```{r init, echo=F}
# Check you're in the right directory, change echo to TRUE to output
getwd()
```


# Introduction/Background 

- Heyy

- The Baltic Sea was formed approximately 15,000 years ago, and following its creation the Atlantic herring migrated into the new habitat causing a bottleneck of their gene pool and forming a population that would become the subspecies Baltic herring. 
- This caused a selective sweep in the new population.

- Selective Sweep = The process of a beneficial mutation increasing in frequency and becoming fixed, resulting in less genetic variation in the genome around the mutation.

- the fishes maybe ...

- Selective sweeps can be identified by

- Aim: Locate the peaks and extents of selective sweeps occurring the chromosome 4 of the baltic herring genome

- "A brief introduction to the project (What is it about? What is the purpose of the project?"

---

# Methods Overview

- "A methods overview (describe briefly, e.g using bullet points, what you have done and what data you have used)"

---

# Detailed methods and results: 

- "Walk us through important code snippets or command line calls that you have used"

- "Present what is the input and output, or intermediate results, of the code snippet or command line call you describe."

---

# Check population structure 

1. Extract chromosome 4

```{bash, eval=FALSE, echo=T}
vcftools --gzvcf data/Ch_v2.0.2_79_ind_snpEff.vcf.gz 
--chr chr4 --recode --out data/chr4
```

1. Principal component analysis with PLINK

```{bash, eval=F, echo=T}
plink --vcf data/Ch_v2.0.2_79_ind_snpEff_chr4.vcf 
--double-id  --pca tabs --out data/chr4_pca
```
---
# Read the files into R (skip?)
```{r, message=FALSE, echo=TRUE}
library(tidyverse)

# Read files
eigenvec <- read_tsv(file = eigenvec_path, col_names = F)
eigenval <- scan(file = eigenval_path) 

# Set eigenvec column names
colnames(eigenvec) <- c("ID1", "ID2", 
                        paste0("PC", 1:(ncol(eigenvec)-2)))

# List areas
areas <- c("Atlantic", "Baltic", "SeaofJapan", "BarentsSea", "WhiteSea", "Pacific")

# extract strings from ID1, if it matches any of the ares, put corresponding value in area
eigenvec <- eigenvec %>% 
  mutate(Area = str_extract(ID1, paste(areas, collapse = "|")))
```
---
# Calculate variance and create label (double-skip?)
```{r, variance-label, echo=T}
variance_label <- function(pc, var_vector) {
  # keep PC number
  pc <- as.numeric(sub("\\D+", "", pc))
  # Calculate variance
  variance <- var_vector[pc] / sum(var_vector)
  # Construct label
  label <- paste0("PC", pc, " (", round(variance*100, 2), "%)")
  # Return the label 
  return(label)
}
```
---
# PCA Plot
```{r, fig.height=4, dev='png', echo=T}
ggplot(eigenvec, aes(x = PC1, y = PC2, color = Area)) + 
  geom_point() +
  xlab(variance_label("PC1", eigenval)) + 
  ylab(variance_label("PC2", eigenval))
```
---
# Balsfjord herring are outliers in the Atlantic area
```{r, comment='#', list-outliers}
# Filter the PCA data for the atlantic outliers 
eigenvec %>% filter(PC1 > 0 & Area == "Atlantic") %>% select(ID1)
```
---
# Bash stuff (skip? keep --freq2 command?)
```{bash, comment='#', eval=F, echo=T}
# Get sample names
bcftools query -l chr4.recode.vcf | grep "Baltic" > baltic_samples.txt

bcftools query -l chr4.recode.vcf | grep "Atlantic" | grep -v "Balsfjord" > atlantic_samples.txt

# Produce vcf-files for chr4 where atlantic, baltic, atlantic and balic are kept
vcftools --vcf chr4.recode.vcf -keep atlantic_samples.txt --recode --out chr4_atlantic
vcftools --vcf chr4.recode.vcf -keep baltic_samples.txt --recode --out chr4_baltic

# VCFtools can be used to extract allele frequencies
vcftools --vcf data/chr4_atlantic.recode.vcf --freq2 --out chr4_atlantic
vcftools --vcf data/chr4_baltic.recode.vcf --freq2 --out chr4_baltic
```
---
# Read Allele frequencies into R (skip?)

```{r, comment='#', load-allele-frequencies}
allele_column_names = c("CHROM", "POS", "N_ALLELES", "N_CHR", "A1_FREQ", "A2_FREQ")
allele_column_types = "cddddd"
#Load samples 
atlantic_raw_allele_freq <- read_tsv(file = atlantic_freq_path, skip = 1, col_names = allele_column_names, col_types = allele_column_types)

baltic_raw_allele_freq <- read_tsv(file = baltic_freq_path, skip = 1, col_names = allele_column_names, col_types = allele_column_types)
```

```{r select-allele-frequencies, comment='#'}
#Select important, add identifier
atlantic_allele_freq <- atlantic_raw_allele_freq %>% 
  select(POS, FREQ = A2_FREQ) %>% 
  mutate(ID = "Atlantic Alt Allele Freq")

baltic_allele_freq <- baltic_raw_allele_freq %>% 
  select(POS, FREQ = A2_FREQ) %>% 
  mutate(ID = "Baltic Alt Allele Freq")
```
---
# Calculate delta and window-size (skip windows?)

```{r delta-allele-frequencies, comment='#'}
delta_allele_freq <- atlantic_allele_freq %>% select(POS)

#Calculate delta allele frequency
delta_allele_freq <- delta_allele_freq %>% 
  mutate(
    FREQ = abs(atlantic_allele_freq$FREQ - #<<
                 baltic_allele_freq$FREQ), #<< 
    ID = "Delta Allele Freq")
```

```{r combine-and-break-size, comment='#'}
#Combine and set a window size (skip?)
combined_allele_freq <- rbind(atlantic_allele_freq, 
                       baltic_allele_freq, 
                       delta_allele_freq)
window_size = 1000 #<<

# Calculates break size based on window size 
break_size <- function(positions, window_size) {
  breaks <- (max(positions) - min(positions)) / (window_size)
  return(breaks) }
```

---
# Plot allele frequencies (all or just delta?)
```{r, message=FALSE, warning=FALSE,fig.width=14,fig.height=5, dev='png'}
combined_allele_freq %>%
  group_by(gr = cut(POS, break_size(POS, window_size)), ID) %>% #<<
  summarize(`Position (Mb)` = mean(POS/1e6), `Mean Frequency` = mean(FREQ)) %>%
  ggplot(aes(`Position (Mb)`,`Mean Frequency`, col = ID)) + 
  geom_jitter(width = 0, height = 0.03, size = .1, alpha = .3) + 
  facet_wrap(~ID, ncol = 3)
```
---
# Heterozygosity (skip/keep?)
.tiny[
```{bash, calculate-het, eval=F}
vctools --vcf chr4_atlantic.vcf --keep data/atlantic_samples.txt --hardy --out chr4_atlantic_het
vctools --vcf chr4_atlantic.vcf --keep data/atlantic_samples.txt --hardy --out chr4_atlantic_het
```

```{r, eval = T, message=F, warning=F, echo=T}
# Load heterozygosity 
atlantic_raw_het_freq <- read_tsv(atlantic_het_path)
baltic_raw_het_freq <- read_tsv(baltic_het_path)

# Separate `OBS(HOM1/HET/HOM2)` column, calculate frequency and select important
atlantic_het_freq <- atlantic_raw_het_freq %>% 
  separate(`OBS(HOM1/HET/HOM2)`, c("OBS_HOM1", "OBS_HET", "OBS_HOM2"), convert = T) %>%
  mutate(TOT_OBS = OBS_HOM1 + OBS_HET + OBS_HOM2, #<<
         FREQ = OBS_HET / TOT_OBS, #<<
         ID = "Atlantic Obs Het Freq") %>%
  select(POS, FREQ, ID, TOT_OBS)

baltic_het_freq <- baltic_raw_het_freq %>% 
  separate(`OBS(HOM1/HET/HOM2)`, c("OBS_HOM1", "OBS_HET", "OBS_HOM2"), convert = T) %>%
  mutate(TOT_OBS = OBS_HOM1 + OBS_HET + OBS_HOM2, 
         FREQ = OBS_HET / TOT_OBS,
         ID = "Baltic Obs Het Freq") %>%
  select(POS, FREQ, ID, TOT_OBS)

# Initialize delta df with POS
delta_het_freq <- atlantic_het_freq %>% select(POS)

# Calculate delta 
delta_het_freq <- delta_het_freq %>% 
  mutate(FREQ = abs(atlantic_het_freq$FREQ - baltic_het_freq$FREQ), 
         ID = "Delta Obs Het Freq")

atlantic_baltic_het_freq <- rbind(atlantic_het_freq, baltic_het_freq)
```
]
---
# Missing observations 
```{r, missingness-plot, message=F, fig.height=4, dev='png'}
atlantic_baltic_het_freq %>%
  group_by(gr = cut(POS, break_size(POS, 1e5)), ID) %>%
  summarize(`Position (Mb)` = mean(POS/1e6), `Mean missingness` = mean(1-TOT_OBS/max(TOT_OBS))) %>%
  ggplot(aes(`Position (Mb)`,`Mean missingness`, col = ID)) + 
  geom_line()
```
---
# Filter on missing data (keep?)
```{r, comment='#', filter-missingness}
# Choose a filter threshold, % of max
filter_threshold = 1

# Keep positions 
positions_to_keep <- inner_join(atlantic_het_freq, baltic_het_freq, by = "POS") %>%
  filter(
    TOT_OBS.x >= filter_threshold * max(TOT_OBS.x) & #<<
    TOT_OBS.y >= filter_threshold * max(TOT_OBS.y)   #<<
    ) %>% 
  select(POS)
```

```{r, remove-tot-obs, comment='#', echo=F}
# Remove the TOT_OBS column to be able to combine with delta_het_freq and plot without changing the code
atlantic_het_freq2 <- atlantic_het_freq %>% select(POS, FREQ, ID)
baltic_het_freq2 <- baltic_het_freq %>% select(POS, FREQ, ID)
```
---
# after removing bad SNPs (only delta?)
```{r, message=FALSE, warning=FALSE,fig.width=14,fig.height=5, dev='png'}
combined_allele_freq %>%
  filter(POS %in% positions_to_keep$POS) %>% #<<
  group_by(gr = cut(POS, break_size(POS, window_size)), ID) %>% 
  summarize(`Position (Mb)` = mean(POS/1e6), `Mean Frequency` = mean(FREQ)) %>%
  ggplot(aes(`Position (Mb)`,`Mean Frequency`, col = ID)) + 
  geom_jitter(width = 0, height = 0.03, size = .1, alpha = .3) + 
  facet_wrap(~ID, ncol = 3) + theme_minimal()
```

???

Mention here the delta-freq peak

---
# Annotation

```{bash bcftools-ann, eval=F, echo=F}
# To get the annotations from the VCF-file
bcftools query -f "%POS\t%ANN\n" chr4.vcf > output.txt
```

```{r,comment='#', eval=T, echo=F}

# The function has to be here for the code to be able to run,
# But we don't want to display it, so I added a second code block,
# Displaying the code on the next slide
annotate_positions <- function(input_df, annotation_df) {
  
  # Filter positions which should be annotated 
  filtered_annotations <- annotation_df %>%   
    filter(POS %in% input_df$POS)
  
  # This info can be found in the VCF file 
  snpEff_column_names <- c("Allele","Annotation","Annotation_Impact","Gene_Name","Gene_ID","Feature_Type","Feature_ID","Transcript_BioType","Rank","HGVS.c","HGVS.p","cDNA.pos / cDNA.length","CDS.pos / CDS.length","AA.pos / AA.length","Distance","ERRORS / WARNINGS / INFO")   
  
  untangled_annotations <- filtered_annotations %>%
    mutate(ANN = str_split(ANN, ",")) %>%         # Split the ANN column into a list of annotations
    unnest(ANN) %>%                               # create rows for each position - annotation pair
    group_by(POS) %>%                             # group by position
    mutate(Annotation_ID = seq_along(POS), 
           .after = POS) %>%                      # assign a number to each annotation
    ungroup() %>%                                 # ungroup the values again 
    separate(ANN, into = snpEff_column_names,     # separate the ANN column
             sep = "\\|")                         # into columns based on SnpEff information
  
  # join annotations to input df by position
  output_df <- inner_join(input_df, untangled_annotations, by = "POS")  
  
  return(output_df)
}
```

```{r read-annotations-filter-positions, comment='#', eval=T, message=F}
# you could also use read_delim, but its (~9x) slower in this case
library(vroom) 

annotation <- vroom(annotations_path, delim = "\t", col_names = c("POS", "ANN"))

# Filter on frequency (and pos) takes to long time to annotate all positions and we don't need to 
significant_positions <- delta_allele_freq %>% 
  filter(between(POS, 0.9e7, 1.3e7)) %>% #<<
  filter(FREQ > 0.6) #<<

# Remove SNPs with high missingess by only keeping those that are in positions_to_keep
# Before running the annotate_positions functions
annotated_positions <- significant_positions %>%
  filter(POS %in% positions_to_keep$POS) %>%
  annotate_positions(annotation) #<< 
```
---
# annotate_positions()
.tiny[
```{r,comment='#', eval = T, message=F}
annotate_positions <- function(input_df, annotation_df) {
  
  # Filter positions which should be annotated 
  filtered_annotations <- annotation_df %>%   
    filter(POS %in% input_df$POS)
  
  # This info can be found in the VCF file 
  snpEff_column_names <- c("Allele","Annotation","Annotation_Impact","Gene_Name","Gene_ID","Feature_Type","Feature_ID","Transcript_BioType","Rank","HGVS.c","HGVS.p","cDNA.pos / cDNA.length","CDS.pos / CDS.length","AA.pos / AA.length","Distance","ERRORS / WARNINGS / INFO")   
  
  untangled_annotations <- filtered_annotations %>%
    mutate(ANN = str_split(ANN, ",")) %>%         # Split the ANN column into a list of annotations
    unnest(ANN) %>%                               # create rows for each position - annotation pair
    group_by(POS) %>%                             # group by position
    mutate(Annotation_ID = seq_along(POS), 
           .after = POS) %>%                      # assign a number to each annotation
    ungroup() %>%                                 # ungroup the values again 
    separate(ANN, into = snpEff_column_names,     # separate the ANN column
             sep = "\\|")                         # into columns based on SnpEff information
  
  # join annotations to input df by position
  output_df <- inner_join(input_df, untangled_annotations, by = "POS")  
  
  return(output_df)
}
```
]
---
# Even more annotation
.nowrap.tiny[
```{r}
annotated_positions %>% print(n = 5)
```
]
.tiny[
```{r}
# Can then filter what we want
annotated_positions %>% group_by(Gene_ID) %>%
  filter(Feature_Type == "transcript") %>% 
  summarize(mean.POS = as.integer(mean(POS)), mean.FREQ = mean(FREQ)) %>%
  select(Gene_ID, POS = mean.POS, FREQ = mean.FREQ)
```
]
---
# biomaRt
.tiny[
```{r biomart, comment='#', message=F}
# A bug in biomaRt overwrites dplyr::select, workaround is to unload dplyr, then load it _after_ biomaRt
detach("package:dplyr")
library(biomaRt)
library(dplyr)

# connect to the herring database
ensembl = useMart("ensembl",dataset="charengus_gene_ensembl")

zfin_ids <- annotated_positions %>%               # Take our annotated positions
  filter(Feature_Type == "transcript" &           # Filter for transcripts
           Annotation != "intron_variant") %>%    # Remove intron_variants
  group_by(Gene_ID) %>%                           # Group by Gene_IDs
  select(POS, FREQ, Gene_ID, ID) %>%                  # Select column we keep from annotation
  summarize(mean.pos = mean(POS), mean.freq = mean(FREQ), Gene_ID, ID) %>% # Summarize like code above
  unique() %>%                                                         # But keep only uniques
  mutate(getBM(attributes=c('ensembl_gene_id', 'zfin_id_symbol'),      # New columns from ensambl
               filters = 'ensembl_gene_id',                            # where the ensembl_gene_id
               values = Gene_ID,                                       # equals the Gene_ID
               mart = ensembl,                                         # chose mart/database
               uniqueRows = F)) %>%                                    # give us everything
  mutate(zfin_id_symbol = ifelse(zfin_id_symbol == "", NA, zfin_id_symbol)) %>% # change "" to NA
  na.omit() %>% # if we want to filter only those genes which has zfin_ids
  select(-ensembl_gene_id)
```
]
---
# biomaRt
```{r zfin-output}
zfin_ids
```
---
```{r combine-data, echo=F}
# Combine data - Commented out combining all of the data 
combined_data <- rbind(atlantic_allele_freq, 
                       atlantic_het_freq2, 
                       baltic_allele_freq, 
                       baltic_het_freq2, 
                       delta_allele_freq,
                       delta_het_freq)
# Combine only the heterozygosity
#combined_data <- rbind(atlantic_het_freq2, baltic_het_freq2, delta_het_freq)

# Filter out data
combined_data <- combined_data %>% filter(POS %in% positions_to_keep$POS)
```
# Summary of the results (change plots? two slides?)
.pull-left[
```{r plot-delta-zfin, eval=T, echo=FALSE, warnings=F, message=F, fig.height=10}
temp <- zfin_ids %>% mutate(ID = "Delta Allele Freq")

library(ggrepel)
combined_data %>%
  filter(POS %in% positions_to_keep$POS) %>%
  filter(ID == "Delta Allele Freq" | ID == "Baltic Obs Het Freq") %>%
  filter(between(POS, .9e7, 1.4e7)) %>%
  mutate(`Position (Mb)` = POS/1e6, `Frequency` = FREQ, col = ID) %>%
  ggplot(aes(`Position (Mb)`, `Frequency`)) + 
  geom_jitter(alpha = .3, size = .3, width = 0, height =.01) + 
  geom_point(data = zfin_ids, aes(x = mean.pos/1e6, y = mean.freq, color = "red"), alpha = 1, size = .3) +
  geom_text_repel(data = zfin_ids, 
                  aes(x = mean.pos/1e6, y = mean.freq, label = zfin_id_symbol), 
                  max.overlaps = Inf, 
                  min.segment.length = 0.5,
                  segment.size = 0.3,
                  box.padding = .2,
                  na.rm = T
                  #segment.color = "red",
                  #arrow = arrow(length = unit(0.07, "inches"), type = "open")
                  ) +# theme(legend.position = "none") + 
  ylab("Delta Allele Freq") + 
  xlab("Chromosome 4 (Mb)") + facet_wrap(~ID, ncol = 1)
  
```
]
.pull-right.nowrap[
```{r list-of-positions}
annotated_positions %>% 
  select(POS, Gene_ID) %>%
  unique()
```
]
---

# Conclusion

- "Conclusions (What do the results tell us?)."

- "Also comment on the project and the methods you used." 

- "Could you have done it in a different way? What difficulties did you encounter? etc."

---

class: center, top
background-image: url("https://upload.wikimedia.org/wikipedia/commons/c/c5/Clupea_harengus_Gervais.flipped.jpg")
background-size: contain

# Thanks!

